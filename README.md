# LLM Chat Assistant ğŸ¤–

ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„å¤šæ¨¡å‹å¤§è¯­è¨€æ¨¡å‹èŠå¤©åŠ©æ‰‹ï¼Œæ”¯æŒ OpenAIã€DeepSeek å’Œ Ollama æœ¬åœ°æ¨¡å‹çš„ç»Ÿä¸€æ¥å…¥ã€‚

## âœ¨ ä¸»è¦ç‰¹æ€§

### ğŸ” å®‰å…¨é…ç½®ç®¡ç†
- **AES åŠ å¯†å­˜å‚¨**ï¼šAPI å¯†é’¥é‡‡ç”¨ AES åŠ å¯†å®‰å…¨å­˜å‚¨
- **ç»Ÿä¸€é…ç½®ç®¡ç†**ï¼šé›†ä¸­ç®¡ç†æ‰€æœ‰ API å¯†é’¥ã€URL å’Œæ¨¡å‹é…ç½®
- **ç±»å‹å®‰å…¨éªŒè¯**ï¼šä½¿ç”¨ Pydantic ç¡®ä¿é…ç½®æ•°æ®çš„ç±»å‹å®‰å…¨

### ğŸ¤– å¤šæ¨¡å‹æ”¯æŒ
- **OpenAI API**ï¼šæ”¯æŒ GPT-4oã€GPT-4o-miniã€GPT-3.5 ç³»åˆ—æ¨¡å‹
- **DeepSeek API**ï¼šé›†æˆ DeepSeek Chat æ¨¡å‹
- **Ollama æœ¬åœ°æ¨¡å‹**ï¼šæ”¯æŒæœ¬åœ°éƒ¨ç½²çš„å¼€æºæ¨¡å‹

### ğŸ¨ ç”¨æˆ·ä½“éªŒä¼˜åŒ–
- **å½©è‰²æ—¥å¿—ç³»ç»Ÿ**ï¼šå¤šçº§åˆ«å½©è‰²æ—¥å¿—è¾“å‡ºï¼Œä¾¿äºè°ƒè¯•å’Œç›‘æ§
- **å…³é”®å­—é«˜äº®**ï¼šæ”¯æŒæ–‡æœ¬å…³é”®å­—é«˜äº®æ˜¾ç¤º
- **è¯¦ç»†é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸æ•è·å’Œé”™è¯¯æç¤º

### ğŸ’¬ èŠå¤©åŠŸèƒ½
- **ç»Ÿä¸€æ¥å£**ï¼šæ ‡å‡†åŒ–çš„èŠå¤© API æ¥å£
- **ä¼šè¯ç®¡ç†**ï¼šæ”¯æŒ session_id è¿›è¡Œå¯¹è¯è®°å¿†
- **æµå¼å“åº”**ï¼šæ”¯æŒæµå¼å’Œéæµå¼ä¸¤ç§å“åº”æ¨¡å¼

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚
- Python 3.8+
- è™šæ‹Ÿç¯å¢ƒï¼ˆæ¨èä½¿ç”¨ `devoops` ç¯å¢ƒï¼‰

### å®‰è£…ä¾èµ–
```bash
pip install openai requests pycryptodome colorama pydantic
```

### é…ç½®è®¾ç½®

1. **ä¿®æ”¹é…ç½®æ–‡ä»¶** `configs/config.json`ï¼š
   ```json
   {
     "secret": {
       "KEY": "your-aes-key",
       "IV": "your-aes-iv"
     },
     "api_key": {
       "OPENAI_API_KEY": "encrypted-openai-key",
       "DEEPSEEK_API_KEY": "encrypted-deepseek-key"
     },
     "api_url": {
       "DEEPSEEK_BASE_URL": "https://api.deepseek.com",
       "OLLAMA_BASE_URL": "http://127.0.0.1:11434/api/generate",
       "OLLAMA_CHAT_URL": "http://127.0.0.1:11434/api/chat/completions"
     }
   }
   ```

2. **åˆå§‹åŒ–é¡¹ç›®**ï¼š
   ```python
   from main import init
   init()  # åˆå§‹åŒ–ç¯å¢ƒå˜é‡å’Œé…ç½®
   ```

## ğŸ“– ä½¿ç”¨ç¤ºä¾‹

### OpenAI API è°ƒç”¨
```python
import config
from openai import OpenAI
from main import init

init()  # åˆå§‹åŒ–é…ç½®

client = OpenAI()
response = client.chat.completions.create(
    model=config.CONFIG_ONLINE_MODELS.OPENAI_MODEL,
    messages=[
        {"role": "user", "content": "Hello, how are you?"}
    ]
)
print(response.choices[0].message.content)
```

### DeepSeek API è°ƒç”¨
```python
import config
from openai import OpenAI
from main import init

init()

client = OpenAI(
    api_key=config.API_KEY.DEEPSEEK_API_KEY,
    base_url=config.API_URL.DEEPSEEK_BASE_URL
)
response = client.chat.completions.create(
    model=config.CONFIG_ONLINE_MODELS.DEEPSEEK_MODEL,
    messages=[
        {"role": "system", "content": "You are a helpful assistant"},
        {"role": "user", "content": "Hello"},
    ]
)
print(response.choices[0].message.content)
```

### Ollama æœ¬åœ°æ¨¡å‹è°ƒç”¨
```python
import config
import requests
from main import init

init()

data = {
    "model": config.CONFIG_LOCAL_MODELS.DEEPSEEK_MODEL,
    "prompt": "è§£é‡Šä¸€ä¸‹æœºå™¨å­¦ä¹ çš„åŸºæœ¬æ¦‚å¿µ",
}
response = requests.post(
    config.API_URL.OLLAMA_BASE_URL,
    json=data
)
print(response.json())
```

### ä½¿ç”¨ç»Ÿä¸€èŠå¤©æ¥å£
```python
from functions.llm.chat import generate_code
from classes.prompt import PromptRequest

request = PromptRequest(
    prompt="å†™ä¸€ä¸ªPythonæ’åºç®—æ³•",
    session_id="user_001",
    stream=False
)
result = generate_code(request)
print(result)
```

## ğŸ“ é¡¹ç›®ç»“æ„

```
llm_chat_assistant/
â”œâ”€â”€ main.py                 # é¡¹ç›®åˆå§‹åŒ–å…¥å£
â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†æ¨¡å—
â”œâ”€â”€ llm_chat.ipynb         # Jupyter æ¼”ç¤ºç¬”è®°æœ¬
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.json        # ä¸»é…ç½®æ–‡ä»¶
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ logger.py          # æ—¥å¿—ç³»ç»Ÿ
â”‚   â””â”€â”€ color.py           # é¢œè‰²å·¥å…·
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ load_json.py       # JSON é…ç½®åŠ è½½
â”‚   â””â”€â”€ secret.py          # åŠ å¯†è§£å¯†å·¥å…·
â”œâ”€â”€ classes/
â”‚   â”œâ”€â”€ config.py          # é…ç½®æ•°æ®æ¨¡å‹
â”‚   â””â”€â”€ prompt.py          # è¯·æ±‚æ•°æ®æ¨¡å‹
â””â”€â”€ functions/
    â””â”€â”€ llm/
        â””â”€â”€ chat.py        # èŠå¤©åŠŸèƒ½å®ç°
```

## ğŸ›  ä¸»è¦æ¨¡å—è¯´æ˜

### é…ç½®ç®¡ç† (`config.py`)
- ç»Ÿä¸€åŠ è½½å’Œç®¡ç†æ‰€æœ‰é…ç½®é¡¹
- è‡ªåŠ¨è§£å¯† API å¯†é’¥
- ç±»å‹å®‰å…¨çš„é…ç½®éªŒè¯

### æ—¥å¿—ç³»ç»Ÿ (`components/logger.py`)
- å¤šçº§åˆ«æ—¥å¿—æ”¯æŒï¼ˆDEBUGã€INFOã€WARNINGã€ERRORã€CRITICALï¼‰
- å½©è‰²ç»ˆç«¯è¾“å‡º
- è¯¦ç»†çš„è°ƒç”¨ä½ç½®ä¿¡æ¯

### å®‰å…¨å·¥å…· (`tools/secret.py`)
- AES åŠ å¯†/è§£å¯†åŠŸèƒ½
- ä¿æŠ¤æ•æ„Ÿé…ç½®ä¿¡æ¯

### èŠå¤©åŠŸèƒ½ (`functions/llm/chat.py`)
- ç»Ÿä¸€çš„æ¨¡å‹è°ƒç”¨æ¥å£
- æ ‡å‡†åŒ–çš„è¯·æ±‚/å“åº”æ ¼å¼
- å®Œæ•´çš„é”™è¯¯å¤„ç†æœºåˆ¶

## ğŸ“‹ æ”¯æŒçš„æ¨¡å‹

### åœ¨çº¿æ¨¡å‹
- **OpenAI**: GPT-4o, GPT-4o-mini, GPT-3.5-turbo ç³»åˆ—
- **DeepSeek**: deepseek-chat

### æœ¬åœ°æ¨¡å‹ (Ollama)
- **DeepSeek**: deepseek-scaler, deepseek-r1
- å…¶ä»–å…¼å®¹ Ollama çš„å¼€æºæ¨¡å‹

## ğŸ”§ é«˜çº§é…ç½®

### è‡ªå®šä¹‰æ—¥å¿—çº§åˆ«
```python
from components.logger import get_module_logger

logger = get_module_logger("my_module")
logger.info("è‡ªå®šä¹‰æ¨¡å—æ—¥å¿—")
```

### å¯†é’¥åŠ å¯†å­˜å‚¨
```python
from tools.secret import encrypt_aes, decrypt_aes

# åŠ å¯†æ–°çš„ API å¯†é’¥
encrypted_key = encrypt_aes("your-api-key")
print(encrypted_key)

# è§£å¯†ä½¿ç”¨
decrypted_key = decrypt_aes(encrypted_key)
```

## ğŸ“ å¼€å‘è¯´æ˜

- æœ¬é¡¹ç›®åœ¨ macOS ç¯å¢ƒä¸‹å¼€å‘
- æ¨èä½¿ç”¨ `devoops` è™šæ‹Ÿç¯å¢ƒ
- ä»£ç æ³¨é‡Šé‡‡ç”¨ JSDoc é£æ ¼
- å‰ç«¯ä»£ç ä½¿ç”¨ ES6 è¯­æ³•æ ‡å‡†

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork æœ¬é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

---

ğŸŒŸ **å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹æ‚¨æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ª Starï¼**
